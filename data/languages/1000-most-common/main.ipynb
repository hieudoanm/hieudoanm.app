{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import concurrent.futures\n",
    "import os\n",
    "import pandas\n",
    "import requests\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEOUT = 30\n",
    "LANGUAGES_URL = \"https://1000mostcommonwords.com/languages/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_response = requests.get(LANGUAGES_URL, timeout=TIMEOUT)\n",
    "languages_html = languages_response.text\n",
    "languages_soup = BeautifulSoup(languages_html, \"html.parser\")\n",
    "list_items = languages_soup.find_all(\"li\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get 1000 Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(list, n):\n",
    "    # looping till length l\n",
    "    for i in range(0, len(list), n):\n",
    "        yield list[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(link : str, column : str):\n",
    "    try:\n",
    "        response = requests.get(link, timeout=TIMEOUT)\n",
    "        html = response.text\n",
    "        beautiful_soup = BeautifulSoup(html, \"html.parser\")\n",
    "        tables = beautiful_soup.find_all(\"table\")\n",
    "        words = []\n",
    "        # Process Tablee\n",
    "        for index, table in enumerate(tables):\n",
    "            rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "            for row in rows:\n",
    "                cells = row.find_all(\"td\")\n",
    "                cells_list = list(cells)\n",
    "                number_text = cells_list[0].getText().strip().lower()\n",
    "                language_text = cells_list[1].getText().strip().lower()\n",
    "                english_text = cells_list[2].getText().strip().lower()\n",
    "                if \"number\" != number_text:\n",
    "                    word = {}\n",
    "                    word[\"english\"] = english_text\n",
    "                    word[column] = language_text\n",
    "                    words.append(word)\n",
    "        sorted_words = sorted(words, key=lambda h: h['english'])\n",
    "        return sorted_words\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23820c8e2a1d43cfb0d38002691db290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link https://1000mostcommonwords.com/words/1000-most-common-amharic-words/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925ae8b774bd48069b5d54dfbf6d3cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f889c42f128b4bc0886dc3891efb8864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e169977ece4af18b59817a8c63f56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d899b5ccc5465182c4aca0da29bb41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49ba1bd0fe444a187668c77e51b92e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b56f5cfc7af42b981bbad948bfb19c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "languages = []\n",
    "\n",
    "chunks_list_items = chunks(list_items, 20)\n",
    "\n",
    "for chunk_list_items in chunks_list_items:\n",
    "    for list_item in tqdm_notebook(chunk_list_items):\n",
    "        anchor = list_item.find(\"a\", href=True)\n",
    "        language = anchor.text.lower()\n",
    "        file_name = \"-\".join(language.split(\" \"))\n",
    "        column = \"_\".join(language.split(\" \"))\n",
    "        link = anchor.get(\"href\", \"\")\n",
    "        if \"1000-most-common\" in link and language != \"english\":\n",
    "            try:\n",
    "                words = get_words(link, column)\n",
    "                languages.append(language)\n",
    "                words_data_frame = pandas.DataFrame(words)\n",
    "                words_data_frame = words_data_frame.drop_duplicates()\n",
    "                words_data_frame = words_data_frame.sort_values(by = [\"english\"])\n",
    "                words_data_frame.to_csv(f\"./languages/{language}.csv\", index = False, header = True)\n",
    "            except:\n",
    "                print(\"link\", link)\n",
    "\n",
    "languages.sort()\n",
    "\n",
    "with open('./languages.txt', 'w') as file_open:\n",
    "    file_open.write('\\n'.join(languages))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_data_frame = pandas.read_csv(\"./languages/french.csv\")\n",
    "korean_data_frame = pandas.read_csv(\"./languages/korean.csv\")\n",
    "spanish_data_frame = pandas.read_csv(\"./languages/spanish.csv\")\n",
    "vietnamese_data_frame = pandas.read_csv(\"./languages/vietnamese.csv\")\n",
    "\n",
    "merged_data_frame = pandas.merge(french_data_frame, korean_data_frame, on=\"english\", how=\"inner\")\n",
    "merged_data_frame = pandas.merge(merged_data_frame, spanish_data_frame, on=\"english\", how=\"inner\")\n",
    "merged_data_frame = pandas.merge(merged_data_frame, vietnamese_data_frame, on=\"english\", how=\"inner\")\n",
    "\n",
    "merged_data_frame.to_csv(\"./words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english\n",
       "a         1\n",
       "region    1\n",
       "rain      1\n",
       "raise     1\n",
       "ran       1\n",
       "         ..\n",
       "glad      1\n",
       "glass     1\n",
       "go        1\n",
       "gold      1\n",
       "your      1\n",
       "Name: count, Length: 999, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_series = merged_data_frame[\"english\"].value_counts()\n",
    "english_series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
