{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import concurrent.futures\n",
    "import os\n",
    "import pandas\n",
    "import requests\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEOUT = 30\n",
    "LANGUAGES_URL = \"https://1000mostcommonwords.com/languages/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_response = requests.get(LANGUAGES_URL, timeout=TIMEOUT)\n",
    "languages_html = languages_response.text\n",
    "languages_soup = BeautifulSoup(languages_html, \"html.parser\")\n",
    "list_items = languages_soup.find_all(\"li\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get 1000 Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(list, n):\n",
    "    # looping till length l\n",
    "    for i in range(0, len(list), n):\n",
    "        yield list[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(link : str, column : str):\n",
    "    try:\n",
    "        response = requests.get(link, timeout=TIMEOUT)\n",
    "        html = response.text\n",
    "        beautiful_soup = BeautifulSoup(html, \"html.parser\")\n",
    "        tables = beautiful_soup.find_all(\"table\")\n",
    "        words = []\n",
    "        # Process Tablee\n",
    "        for index, table in enumerate(tables):\n",
    "            rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "            for row in rows:\n",
    "                cells = row.find_all(\"td\")\n",
    "                cells_list = list(cells)\n",
    "                number_text = cells_list[0].getText().strip().lower()\n",
    "                language_text = cells_list[1].getText().strip().lower()\n",
    "                english_text = cells_list[2].getText().strip().lower()\n",
    "                if \"number\" != number_text:\n",
    "                    word = {}\n",
    "                    word[\"english\"] = english_text\n",
    "                    word[column] = language_text\n",
    "                    words.append(word)\n",
    "        sorted_words = sorted(words, key=lambda h: h['english'])\n",
    "        return sorted_words\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4269e1a03e54369bd3e35bf79d43158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732b45df3a2346bba617046ce8265c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'english'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/hieudoan/git/github.com/hieudoanm/HouseOfMystery/data/languages/1000-most-common/main.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hieudoan/git/github.com/hieudoanm/HouseOfMystery/data/languages/1000-most-common/main.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m             words_data_frame \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mDataFrame(words)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hieudoan/git/github.com/hieudoanm/HouseOfMystery/data/languages/1000-most-common/main.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m             words_data_frame \u001b[39m=\u001b[39m words_data_frame\u001b[39m.\u001b[39mdrop_duplicates()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hieudoan/git/github.com/hieudoanm/HouseOfMystery/data/languages/1000-most-common/main.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m             words_data_frame \u001b[39m=\u001b[39m words_data_frame\u001b[39m.\u001b[39;49msort_values(by \u001b[39m=\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39menglish\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hieudoan/git/github.com/hieudoanm/HouseOfMystery/data/languages/1000-most-common/main.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m             words_data_frame\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./languages/\u001b[39m\u001b[39m{\u001b[39;00mlanguage\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m, index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, header \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hieudoan/git/github.com/hieudoanm/HouseOfMystery/data/languages/1000-most-common/main.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m languages\u001b[39m.\u001b[39msort()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:6758\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6754\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(by):\n\u001b[1;32m   6755\u001b[0m     \u001b[39m# len(by) == 1\u001b[39;00m\n\u001b[1;32m   6757\u001b[0m     by \u001b[39m=\u001b[39m by[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 6758\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label_or_level_values(by, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   6760\u001b[0m     \u001b[39m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[1;32m   6761\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   6762\u001b[0m         \u001b[39m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[1;32m   6763\u001b[0m         \u001b[39m# \"Series\", variable has type \"ndarray\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/generic.py:1778\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1776\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mget_level_values(key)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1777\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1778\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1780\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'english'"
     ]
    }
   ],
   "source": [
    "languages = []\n",
    "\n",
    "chunks_list_items = chunks(list_items, 10)\n",
    "\n",
    "for chunk_list_items in chunks_list_items:\n",
    "    for list_item in tqdm_notebook(chunk_list_items):\n",
    "        anchor = list_item.find(\"a\", href=True)\n",
    "        language = anchor.text.lower()\n",
    "        file_name = \"-\".join(language.split(\" \"))\n",
    "        column = \"_\".join(language.split(\" \"))\n",
    "        link = anchor.get(\"href\", \"\")\n",
    "        if \"1000-most-common\" in link:\n",
    "            words = get_words(link, column)\n",
    "            languages.append(language)\n",
    "            words_data_frame = pandas.DataFrame(words)\n",
    "            words_data_frame = words_data_frame.drop_duplicates()\n",
    "            words_data_frame = words_data_frame.sort_values(by = [\"english\"])\n",
    "            words_data_frame.to_csv(f\"./languages/{language}.csv\", index = False, header = True)\n",
    "\n",
    "languages.sort()\n",
    "\n",
    "with open('./languages.txt', 'w') as file_open:\n",
    "    file_open.write('\\n'.join(languages))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_data_frame = pandas.read_csv(\"./languages/french.csv\")\n",
    "korean_data_frame = pandas.read_csv(\"./languages/korean.csv\")\n",
    "spanish_data_frame = pandas.read_csv(\"./languages/spanish.csv\")\n",
    "vietnamese_data_frame = pandas.read_csv(\"./languages/vietnamese.csv\")\n",
    "\n",
    "merged_data_frame = pandas.merge(french_data_frame, korean_data_frame, on=\"english\", how=\"inner\")\n",
    "merged_data_frame = pandas.merge(merged_data_frame, spanish_data_frame, on=\"english\", how=\"inner\")\n",
    "merged_data_frame = pandas.merge(merged_data_frame, vietnamese_data_frame, on=\"english\", how=\"inner\")\n",
    "\n",
    "merged_data_frame.to_csv(\"./words.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english\n",
       "a         1\n",
       "region    1\n",
       "rain      1\n",
       "raise     1\n",
       "ran       1\n",
       "         ..\n",
       "glad      1\n",
       "glass     1\n",
       "go        1\n",
       "gold      1\n",
       "your      1\n",
       "Name: count, Length: 999, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_series = merged_data_frame[\"english\"].value_counts()\n",
    "english_series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
